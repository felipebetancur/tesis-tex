\documentclass[12pt,oneside]{book}

\usepackage{ulamonog} % formato para la propuesta o proyecto de grado
\usepackage[ansinew]{inputenc} % escribir acentos



%\usepackage[activeacute,spanish]{babel}

\usepackage{color}
\usepackage[colorlinks]{hyperref}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\definecolor{light-gray}{gray}{0.95}
\usepackage{listings}

% ***************************************************************** %
% En el siguiente comando se pueden modificar:
% Titulo, Autor, Palabras clave
% ***************************************************************** %

% si se va a imprimir,
% se incluye al final despues de citecolor=blue, el comando draft=true
% Las siguientes son propiedades del pdf, mï¿½s no cambian nada dentro del
% texto de la monografï¿½a
\hypersetup{pdftitle={Propuesta de Tesis},
pdfauthor={Jesús Gómez},
pdfsubject={Propuesta de Proyecto de Grado}, % se deja igual (se cambia para el proyecto de grado)
pdfkeywords={ Monitoreo de redes, Calidad de servicio, Big Data, Benchmarking, Cloud}, pdfstartview=FitH,
bookmarks=true, citecolor=blue}%, draft=true}

% ***************************************************************** %
% FIN DE
% Titulo, Autor, Palabras clave
% ***************************************************************** %

% Si desea que no aparezca la lista de tablas o figuras descomente las siguientes lineas
\nolistoftables
\nolistoffigures

%\usepackage{natbib}

\sloppy

\begin{document}

\frontmatter


% ***************************************************************** %
% Portada y resumen
% ***************************************************************** %

% Si desea que el logo de la ULA aparezca en la parte superior,
% descomente la siguiente lï¿½nea. Por defecto aparece en la parte inferior
\logoarriba{}

% Aï¿½o en el cual se entrega el proyecto de grado o la propuesta
\copyrightyear{2015}

% Al final cuando hayan presentado, sin comentar,
% deberia ser el nï¿½mero de tesis presentada y la opciï¿½n, IO por ejemplo
% (Actualmente, 11-03-08, no se estï¿½ trabajando con esta metodologï¿½a de llevar un
% nï¿½mero de proyecto para las tesis, por lo cual debe ir comentado)
%\numproy{00IO}

% En caso de hacer la propuesta, descomente la siguiente
% instrucciï¿½n. Para el Proyecto de Grado debe comentarse. Modifica
% tanto la categorï¿½a de la monografï¿½a, como la apariciï¿½n de
% "Presentado ante la ilustre Universidad de Los Andes
% como requisito parcial para obtener el Tï¿½tulo de" en la portada
%\tipomonografia{Propuesta de Proyecto de Gradooo}


% Tï¿½tulo de la monografï¿½a, el cual saldrï¿½ en la portada
\title{Diseño e implementación de un sistema de monitoreo de redes orientado a la recolección masiva de datos.}

% Autor de la monografï¿½a, el cual saldrï¿½ en la portada
 \author{Jesús Alberto Gómez Pérez}

% La fechaentrega, presentaciondia, presentacionlugar
% y mencionespecial, es para aquel caso en el cual se
% vaya a utilizar la hoja del veredicto en el formato
% que se presenta aquï¿½. El primerjurado, segundojurado,
% y cedula, son campos que pueden llenarse, pero sï¿½lo
% aparecerï¿½n si se utiliza la pï¿½gina del veredicto

% Cï¿½dula del autor de la monografï¿½a
 \cedula{XX.XXX.XXX}

% Tutor del Proyecto de Grado
 \tutor{Dr. Andrés Arcia-Moret}

% Cualquiera de los instructores que aparecen a continuaciï¿½n
% pueden comentarse o descomentarse segï¿½n sea el caso:

%%% Cotutor del Proyecto de Grado
% \cotutor{Dra. propuesta}
% \cotutordos{Dra. propuesta dos}
%%% Asesor del Proyecto de Grado
% \asesor{Dr. Asesor}
%%% Asesor Industrial del Proyecto de Grado
% \asesorindustrial{Dr. Asesor Industrial}
%%% Tutor Industrial del Proyecto de Grado
% \tutorindustrial{Dr. Tutor Industrial}
%%% Jurados del Proyecto de Grado
 \primerjurado{Dr. Primer Profesor}
 \segundojurado{Prof. Segundo Profesor}

% ***************************************************************** %
% Si sabe la fecha de presentaciï¿½n
%
% con o sin comentar
% (Esta hoja es un formato para asentar la nota del proyecto de grado;
% sin embargo, la hoja que se utiliza para ese fin, se busca en la escuela
% dï¿½as antes de la presentaciï¿½n)
% ***************************************************************** %
%\fechaentrega{Diciembre 2006} % Si sabe cuando se presentï¿½
%\presentaciondia{7 de Diciembre de 2005} % si conoce exactamente el dï¿½a
%\presentacionlugar{Salï¿½n de reuniones EISULA} % si conoce exactamente el lugar donde se presentï¿½
% ***************************************************************** %
% FIN DE
% Si sabe la fecha de presentaciï¿½n
% ***************************************************************** %


% ***************************************************************** %
% Si tiene mencion especial
% con o sin comentar
% ***************************************************************** %
%\mencionespecial{Este proyecto fue seleccionado como \textbf{mejor
%proyecto de grado} de la Escuela de Ingenierï¿½a de Sistemas, en el
%IC aniversario de la Facultad de Ingenierï¿½a.} % si tiene menciï¿½n especial
% (El texto puede cambiarse \mencionespecial{*********} segï¿½n corresponda
% ***************************************************************** %
% FIN DE
% Si tiene mencion especial
% con o sin comentar
% ***************************************************************** %

% NO TOCAR si es Ingenieria de Sistemas
% \grado{Ingeniero Quï¿½mico} % por defecto Ingeniero de Sistemas

%\signaturepage ----- NO TOCAR

%%%%%OJO%%%%%Arreglen esto segï¿½n su opciï¿½n
% Si es control y automatizacion se comentan las siguientes lï¿½neas. Si es de
% Sistemas Computacionales comenta la tercera. De Investigaciï¿½n de Operaciones
% comenta la segunda
\opcion{Sistemas Computacionales}
% \opcion{Investigaciï¿½n de Operaciones}

% Aquï¿½ se escribe el resumen de la monografía
\resumen{En el presente proyecto se plantea el desarrollo de un sistema de monitoreo distribuido de enlaces críticos de redes a través de un servicio web centralizado. Este servicio además pretende hacer énfasis en la visualización de los datos recolectados a partir de pruebas periódicas. El sistema está planteado como una herramienta para facilitar el entendimiento del funcionamiento de la red y ofrecer una solución centralizada, de muy bajo costo y con componentes de hardware que puedan estar desatendidos.}

% Aquï¿½ se escriben las palabras claves de la monografï¿½a
\descriptores{Monitoreo de redes, Calidad de servicio, Big Data, Benchmarking, Cloud}

% Esto es para que salga la cota en la hoja del resumen. Actualmente,
% 11-03-08, en la Escuela de Ingenierï¿½a de Sistemas no es necesario
% buscar la cota previamente, sino que el Proyecto de Grado se entrega
% en la Escuela sin cota.
%\cota{IXD A01.1}

% Si desea eliminar la frase "Este trabajo fue procesado en LATEX"
% del resumen, descomente la siguiente lï¿½nea
\sinlatex{}

% ***************************************************************** %
% FIN DE
% Portada y resumen
% ***************************************************************** %


% ***************************************************************** %
% Si tiene dedicatoria
% con o sin comentar
% ***************************************************************** %
%\dedicatoria{A todos los amados seres\\ cuando son dos lï¿½neas o mï¿½s}
% ***************************************************************** %
% FIN DE
% Si tiene dedicatoria
% ***************************************************************** %

\beforepreface

% ***************************************************************** %
% Agradecimientos y capï¿½tulos NO numerados
% ***************************************************************** %

%\prefacesection{Agradecimientos}
% Aï¿½n no hay agradecimientos

%%% Capitulo sin numero, antes de la pagina 1

%\prefacesection{Introducciï¿½n}
% Este es un ejemplo de una secciï¿½n no numerada.


% ***************************************************************** %
% FIN DE
% Agradecimientos y capï¿½tulos NO numerados
% ***************************************************************** %

\afterpreface

\pagestyle{fancyplain}
\renewcommand{\chaptermark}[1]{\markboth{#1}{\textsc{\footnotesize\thechapter\ #1}}}
\renewcommand{\sectionmark}[1]{\markright{\textsc{\footnotesize\thesection\ #1}}}
\lhead[\fancyplain{}{\textsc{\footnotesize\thepage}}]%
{\fancyplain{}{\rightmark}}
\rhead[\fancyplain{}{\leftmark}]%
{\fancyplain{}{\textsc{\footnotesize\thepage}}} \cfoot{}

\mainmatter

% ***************************************************************** %
% Cuerpo
% ***************************************************************** %
% De aquï¿½ en adelante se desarrollan los capï¿½tulos numerados de la monografï¿½a

% ***************************************************************** %
% INICIO DE estructura tentativa de la Propuesta
% ***************************************************************** %

\chapter{Introducción}

\section{Antecedentes}

Existen dos estrategias de monitoreo de redes: monitoreo activo o benchmarking que consiste en generar tráfico para realizar medidas y comprobar la respuesta de la red  y monitoreo pasivo que consiste en escanear el tráfico de la red en ciertos puntos estratégicos para censar el tráfico en la red. El benchmarking tiene la desventaja de tener que inyectar tráfico lo cual puede entorpecer el funcionamiento normal de la red ejemplos de herramientas de benchmarking son ping, iperf y traceroute.

El monitoreo pasivo tiene la ventaja de que nos puede dar una muy buena idea del uso de la red sin embargo para mayor efectividad debe realizarse en nodos intermedios a los que muchas veces no tenemos acceso, ejemplos de herramientas de monitoreo pasivo son tcpdump y wireshark; en ambos casos hay que resaltar que es difícil tener una imagen completa de la realidad de la red.

Uno de los trabajos más importantes en el área de monitoreo de redes es el Protocolo Simple de Administración de Red o SNMP (del inglés Simple Network Management Protocol) este emergió como una de las primeras soluciones al problema de manejo de redes y se ha convertido en la solución más ampliamente aceptada  debido a su diseño modular e independiente de productos o redes específicas. SNMP consiste de (1) un administrador de red, (2) una serie de dispositivos remotos monitoreados (3) bases de información de administración (MIBs) en estos dispositivos, (4) agentes remotos que reportan la información de las MIBs al administrador de red y toman acciones si les indica y (5) un protocolo de comunicación entre los dispositivos \cite{Kurose:13}.

SNMP no solo ofrece al administrador de red reportes sobre cada uno de los dispositivos administrados sino que también permite tomar acción sobre ellos proactivamente antes de que ocurran problemas o de forma reactiva para solucionar problemas cuando ocurren de forma inesperada.

La red de TVWS (TV White Spaces o Espacios blancos en el espectro radioeléctrico) de Malawi fue implementada en el marco de un proyecto para llevar Internet a áreas rurales en países en vías de desarrollo utilizando soluciones de bajo costo a través de los espacios en blanco en el espectro radioeléctrico específicamente en la banda UHF (siglas del inglés Ultra High Frequency, 'frecuencia ultra alta') \cite{Malawi:13}.

Muchas veces esta red debe dejarse desatendida durante largos periodos de tiempo ya que sus nodos son de difícil acceso o es muy costoso tener a profesionales dedicados que se encarguen de su mantenimiento, este escenario hace evidente la necesidad de una solución de monitoreo de redes a distancia y de mínimo mantenimiento. Además es atractivo para el centro de monitoreo de la red poder añadir, modificar o eliminar nodos de interés de manera sencilla a la interfaz de monitoreo.

Para intentar solucionar este problema y recolectar información sobre la red de Malawi se implementó un sistema en dos partes: un monitor de red instalado en la estación base (BS) en Malawi y un servicio web remoto, el monitor en la estación base se conecta a cada uno de los nodos de la red y determina el tiempo de ida y vuelta (RTT por sus siglas en ingles)  de forma automatizada en ciertos intervalos de tiempo, guarda los resultados en archivos y los coloca en una carpeta que se sincroniza a través de un servicio en la nube  de tipo PaaS (Plataforma como servicio) con el servidor web, que a su vez escanea la carpeta compartida y actualiza su base de datos que puede usarse para generar gráficas de RTT promedio y determinar tiempos de actividad continuos y porcentaje de disponibilidad de servicio \cite{MalawiNetMonitor:15}.

A pesar de que este sistema recolecta información útil y presenta gráficas muy sencillas de entender, su programación no permite agregar nuevos nodos, esto trae como consecuencia que debe ser modificado manualmente cuando la red se expande, dando lugar a la necesidad de que el servicio web se pueda expandir para dar servicio a múltiples monitores remotos simultáneamente.

Por estos motivos proponemos la construcción de un sistema de monitoreo a gran escala que llamaremos Octopus Monitor, para hacerlo totalmente configurable y robusto además de agregar una interfaz de configuración vía web que permita manejar usuarios, agregar monitores remotos, agregar nodos y modificar los parámetros de las pruebas, todo esto apoyándonos en un sistema de archivos compartidos a través de la nube.

Mientras que  el mayor valor de Malawinet Monitor es la visualización de grandes volúmenes de datos  que se pueden obtener a partir de pruebas de bajo impacto de tráfico (ping, traceroute), se han realizado otros trabajos en el área de monitoreo de redes como Bowlmap; este es un sistema de monitoreo de redes a través de la visualización de mediciones para el Laboratorio Abierto Inalámbrico de Berlín (BOWL,  por sus siglas en ingles). Este sistema tiene una alta flexibilidad ya que permite realizar cambios en sus pruebas existentes así como agregar pruebas totalmente nuevas y a su vez generar las visualizaciones necesarias para el análisis de dicha información, además tiene la ventaja de solo transmitir la información necesaria para cada actualización lo que acelera las peticiones y permite la visualización de data en tiempo real \cite{Bowlmap:12}.

\section{Planteamiento del Problema}

Las redes de computadoras se componen de un conjunto de nodos interconectados sujetos a numerosos factores que escapan de nuestro control y sobre los que muchas veces no tenemos conocimiento, en otras palabras la red puede llegar a ser impredecible y no ofrece garantías sobre el servicio que ofrece; algunas aplicaciones dependen de una alta disponibilidad y estabilidad por lo que es esencial para un administrador de red tener información del estado de la red, para diagnosticar,  solucionar problemas y asegurar la calidad de servicio.

Existen muchos otros ejemplos en los que es importante tener datos del estado de la red como en redes de bajo costo en las que pueden ocurrir largas interrupciones de servicio o para un cliente de un servicio de alojamiento web que desea saber si su sitio web está disponible y que tan rápido responde; plataformas como Pingdom \cite{PINGDOM} o UptimeRobot \cite{UPTIMEROBOT} permiten monitorear distintos servicios en Internet y generan alertas cuando encuentran problemas, sin embargo no son gratuitas y no permiten la inclusión de nuevos tipos de pruebas o la visualización masiva de datos históricos.

 Mantener estas mediciones con las herramientas existentes se vuelve una tarea compleja mientras crece el número de nodos a monitorear (es decir, las fuentes de información) y la cantidad de datos aumenta a través del tiempo, sumado a esto solo podemos capturar información a partir de los nodos externos de la red, por lo que en la mayoría de los casos no es posible tener una imagen completa de los enlaces a monitorear.

  A pesar de que Malawinet Network Monitor podría ofrecer estadísticas de tiempo de ida y vuelta (RTT) y disponibilidad de un enlace solo a partir de las trazas capturadas con Ping, se desea además implementar un marco de trabajo que permita agregar nuevas pruebas automatizadas que ayuden a obtener una imagen más completa de la red.
  
\section{Justificacion}
  
Ya que las redes están compuestas de arreglos de nodos conectados entre si y muchas veces resultan de despliegues caóticos y no-coordinados sobre los que no se tiene control o conocimiento y existe una enorme cantidad de variables como 

\section{Objetivos}

\subsection{Objetivos Generales}

Construir un servicio web de monitoreo de redes de bajo costo para países en vías de desarrollo con almacenamiento de datos en la nube de tipo PaaS que sea de fácil instalación y permita configurar múltiples monitores remotos para ajustarse a cambios en las características de las redes a monitorear y la carencia de personal in sitio.

\subsection{Objetivos Específicos}

\begin{itemize}
\item Desarrollar un servicio de monitoreo de bajo costo para países en vías de desarrollo que de servicio a múltiples monitores de red remotos, presente visualizaciones gráficas a partir de los datos recogidos y ofrezca un marco de trabajo para agregar nuestros tipos de pruebas a los monitores de red existentes.
\item Desarrollar un cliente monitor para desplegar en nodos desatendidos con dispositivos recolectores de muestra de bajo costo (ej. Raspberry PI, Alix boards, APU) para observar el comportamiento de los enlaces a través de aplicaciones de monitoreo sencillas y de consola.
\item Utilizar de sistemas de bajo costo y alta disponibilidad en la nube para almacenamiento y transferencia de datos.
\item Integrar los distintos subsistemas que conforman el servicio de monitoreo.
\item Desarrollar un modulo de calculo asíncrono de gráficas que permita mejorar los tiempos de interacción del usuario final con el sistema utilizando técnicas para agilizar cómputo como caching, prefetching, threads, etc.
\end{itemize}

\section{Metodología}

En este trabajo se seguirá una metodología en espiral; el modelo en espiral es un modelo del ciclo de vida del software donde el esfuerzo del desarrollo es iterativo. Cada ciclo de la espiral representa una fase del desarrollo de software, cada uno de los ciclos consiste de los siguientes pasos:
\begin{enumerate}
  \item Determinar o fijar los objetivos. En este paso se definen los objetivos específicos para posteriormente identifica las limitaciones del proceso y del sistema de software, además se diseña una planificación detallada de gestión y se identifican los riesgos.
  \item Análisis del riesgo. En este paso se efectúa un análisis detallado para cada uno de los riesgos identificados del proyecto, se definen los pasos a seguir para reducir los riesgos y luego del análisis de estos riesgos se planean estrategias alternativas.
  \item Desarrollar, verificar y validar. En este tercer paso, después del análisis de riesgo, se eligen un paradigma para el desarrollo del sistema de software y se lo desarrolla.
  \item Planificar. En este último paso es donde el proyecto se revisa y se toma la decisión si se debe continuar con un ciclo posterior al de la espiral. Si se decide continuar, se desarrollan los planes para la siguiente fase del proyecto.
\end{enumerate}

Se realizarán cuatro ciclos, el primero corresponde a la realización de un monitor remoto básico que realice mediciones de RTT de la red con almacenamiento en la nube y visualizaciones de los datos obtenidos.

El segundo ciclo consiste en permitir el monitoreo de una cantidad arbitraria de monitores remotos permitiendo a múltiples usuarios manejar sus monitores remotos desde el servicio web y observar las visualizaciones.

El tercer ciclo corresponde en diseñar e integrar una prueba con otras herramientas (traceroute, iperf, etc) para conseguir puntos comunes y generar un enfoque de integración sencillo de los wrappers futuros a las aplicaciones. (ej. Lidiar con aplicaciones que requieren enfoque cliente solo [ping] o cliente-servidor [iperf]).

El cuarto ciclo consiste en hacer análisis del rendimiento del sistema y hacer las optimizaciones necesarias para ofrecer una calidad de servicio apropiada, determinar costos, limitaciones y requisitos mínimos para implementar en países en vías de desarrollo.

\section{Alcance}



\section{Estructura del Documento}


%
%******************************
%FIN DE CAPITULO I
%******************************
%

\chapter{Marco Teórico}

En este capitulo se presentan los conceptos necesarios para la comprensión de este documento y se describen las herramientas de software, métodos y formatos que se emplearán para el desarrollo del sistema propuesto.

\section{Monitoreo de Redes}

El monitoreo de redes se refiere al uso de sistemas computacionales para determinar el estado de redes de computadoras, el estado de la red puede ser visto como el conjunto de factores o métricas que describen la red en un momento dado, se hablará a detalle de algunas de estas métricas en la sección \ref{sec:metricas}.

Mientras una red tiene ciertos elementos relativamente invariables como la posición de sus nodos, la longitud de los enlaces, el tipo de enlace (fibra óptica, cable, satelital, etc), el ancho de banda de los enlaces, la velocidad de procesamiento de los enrutadores, entre otros, el estado de la red viene determinado por elementos generalmente impredecibles, como condiciones climatológicas, problemas de configuración, equipos en mal estado y congestión, determinar todo este tipo de problemas para generar alertas, aplicar acciones correctivas o al menos tener conocimiento de ellas es el objetivo de un sistema de monitoreo de redes.

Existen dos paradigmas fundamentales en el monitoreo de redes, el monitoreo activo que consiste en generar tráfico y observar la respuesta de la red y el monitoreo pasivo, que consiste en observar el tráfico que atraviesa un cierto enlace o nodo. Para tener una imagen completa de la red es conveniente usar ambos paradigmas ya que ambos pueden ofrecer distintas perspectivas.

\section{Principio Fin-a-Fin}

El principio de fin-a-fin (también llamado argumento de fin-a-fin) sugiere que las funciones en los niveles bajos de un sistema pueden ser redundantes o de poco valor comparadas con el costo de proveerlas a bajo nivel\cite{saltzer1984end}, en otras palabras este argumento recomienda que la complejidad de un sistema de computación distribuido debe estar en los nodos mas externos o de "mayor nivel".

Este principio es valioso para el diseño de cualquier tipo de sistema distribuido sin embargo ha sido fundamental en la expansión y desarrollo de redes de computadoras de propósito general y se sustenta en que los nodos intermedios de una red deben proveer solo las funciones necesarias para permitir la comunicación entre los nodos finales, de esta manera es posible implementar nuevas funcionalides en los extremos de la red sin necesidad de hacer cambios a los nodos intermedios.

En el contexto de monitoreo de redes, se denomina tomografía de redes al proceso de inferir aspectos internos de una red a partir de mediciones realizadas en sus nodos externos.

\section{Métricas de calidad de un enlace} \label{sec:metricas}

A continuación se explican las métricas mas comúnmente utilizadas para determinar la calidad de un enlace.

\subsection{Latencia} \label{sub:lat}

La latencia es el tiempo que le toma a un paquete o mensaje viajar desde su origen hasta el punto destino \cite{Grigorik:13}. Teóricamente la latencia está relacionada directamente con la distancia entre los puntos finales de una comunicación, en la practica los paquetes viajan a través de una red de enrutadores que retransmiten el mensaje hasta su destino, la latencia total será la suma de cada uno de los siguientes factores para cada uno de los enrutadores que atraviese el paquete\cite{Grigorik:13}:
\begin{itemize}
\item{\textbf{Retraso de Propagación:} es el tiempo que tarda un mensaje en viajar del emisor al receptor y es función de la distancia por la velocidad a la que la señal se propaga}
\item{\textbf{Retraso de Transmisión:} es el tiempo que tarda el emisor en poner todos los bits de un mensaje en el medio de transmisión y es función de la longitud del paquete y el ancho de banda del enlace}
\item{\textbf{Retraso de Procesamiento:} tiempo requerido para revisar la cabecera del paquete, buscar errores y determinar el destino del paquete.}
\item{\textbf{Retraso de Colas:} Cantidad de tiempo que un paquete pasa en la cola de una interfaz esperando su turno por ser procesado.}
\end{itemize}

\subsection{Tiempo de ida y vuelta}

El tiempo de ida y vuelta (RTT por sus siglas es ingles) es el tiempo que le toma a un paquete viajar desde el origen a su destino y de vuelta, podría pensarse que el RTT es aproximadamente el resultado de multiplicar la latencia por dos, sin embargo existen factores como el retraso por procesamiento en el equipo destino o diferencias en el enrutamiento del paquete en su camino de vuelta que hace que sea arriesgado establecer esa proposición. 

Uno de los métodos mas populares para medir el RTT es enviar un paquete ICMP Echo Request y esperar el correspondiente ICMP Echo Reply sin embargo también es posible medir el RTT pasivamente durante la transmisión de un flujo TCP usando marcas de tiempo en la cabecera de los mensajes TCP\cite{strowes2013passively}.

Es importante notar que no es lo mismo medir el RTT desde la capa de red con el protocolo ICMP que hacerlo en la capa de transporte con TCP o en la capa de aplicación con un protocolo como HTTP, evidentemente el RTT será mayor en las capas superiores, sin embargo estas métricas también son útiles ya que se acercan mas fielmente a la experiencia del usuario.

\subsection{Perdida de paquetes}

La pérdida de paquetes ocurre cuando los paquetes en una transmisión fallan en llegar a su destino, ya sea por interferencias en el medio de transmisión (por ejemplo obstáculos físicos en un enlace WiFi), o cuando son desechados por un nodo de la red, los paquetes pueden ser desechados si se determina que están corruptos o mas comúnmente debido a escenarios de congestión en los que un enrutador está recibiendo paquetes a una tasa mayor de la que puede retransmitirlos y no tiene mas opción que desechar los paquetes que desborden la cola.

La perdida de paquetes afecta dramáticamente la latencia percibida en la capa de aplicación, según \cite{strowes2013passively} una perdida de paquetes del 5\% puede introducir un retraso de medio segundo en la aplicación. 
 
Mientras puede parecer que la perdida de paquetes es siempre producto de un problema, esta juega un papel vital en el algoritmo de prevención de congestión (congestion avoidance) del protocolo TCP, ayudándolo a detectar congestión en la red el cual responderá limitando su tasa de envío de datos, esto ha sido esencial para evitar el colapso de las redes ip NOTA: Nosotros alguna vez hablamos de esto, valdría la pena nombrar el RFC que lo explica. 

\subsection{Jitter} 

Se llama jitter a la fluctuación de la latencia durante la transmisión de un conjunto de paquetes, estas fluctuaciones vienen dadas principalmente por la variación del retraso que los paquetes experimentan en las colas en los enrutadores\cite{Kurose:13}, sin embargo todos los factores mencionados en la sección \ref{sub:lat} pueden contribuir en menor medida.

El término jitter puede tener distintas connotaciones sin embargo es usado frecuentemente por científicos en el área de la computación como la variación de una métrica (comúnmente latencia) con respecto a otra métrica de referencia (como latencia mínima o promedio), a esto también se le llama variación en el retraso de los paquetes (PDV por sus siglas en ingles), este termino es a veces preferido por ser mas preciso \cite{rfc3393}

El jitter puede afectar considerablemente transmisiones en tiempo real como VoIP o streaming sin embargo la correcta implementación de políticas de buffering del lado del receptor puede minimizar e incluso mitigar este efecto\cite{Kurose:13}

\subsection{Throughput}

En términos de redes de computadoras, el throughput es la tasa en bits por segundo a la que fluyen los datos a través de un enlace \cite{Kurose:13}, el throughput puede compararse al caudal de un rio, donde mientras mas ancho sea el rio mas agua puede fluir a través de el.

El máximo throughput teórico entre un par de nodos esta determinado principalmente por el segmento de la red con menor ancho de banda, este comportamiento se ilustra en la figura \ref{fig:throughput}, donde el cable entre el punto de acceso wifi y el ISP resulta ser el cuello de botella en la comunicación. En la practica el throughput también viene determinado por varios factores como otros flujos de datos con los que se comparte la red o la velocidad a la que el receptor es capaz de procesar el flujo de datos entrante.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{img/throughput}
\caption{Latencia y ancho de banda  Imagen tomada del
	sitio: http://chimera.labs.oreilly.com/books/1230000000545/ch01.html}
\label{fig:throughput}
\end{figure}

Para aplicaciones en tiempo real es esencial tener un throughput mínimo mayor a un cierto umbral que asegure que los datos se estén recibiendo a una tasa mayor o igual a la que se están consumiendo\cite{Kurose:13}, es decir que a partir de esa tasa mínima un mayor throughput no implica una mejoría en la calidad de la comunicación, otras aplicaciones como transferencias de archivos se benefician del mayor throughput posible ya que el tiempo de transferencia es una función del tamaño del archivo entre el throughput durante la transferencia.

No es posible medir el throughput de un enlace de forma pasiva, por lo que las pruebas que existen consisten en inyectar tráfico al enlace hasta saturarlo y determinar la velocidad a la que se reciben los datos del lado del receptor. Existen múltiples maneras de saturar el enlace, por ejemplo speedtest.net \cite{SPEEDTEST} utiliza hasta cuatro hilos paralelos transmitiendo mensajes aleatorios a través de HTTP, utilizar múltiples flujos es una forma efectiva de mitigar el efecto de la latencia sobre el throughput.

A diferencia de las métricas anteriores medir el throughput solo es posible con la colaboración de los nodos extremos del enlace, por lo que es necesario tener algún tipo de software preparado para aceptar la prueba e informar del resultado obtenido.

\subsection{Uso del ancho de banda}

Se le llama uso del ancho de banda a la medida de los datos que fluyen a través de un enlace, generalmente se busca optimizar el uso del ancho de banda para aprovechar al máximo los recursos de red.

Mas allá de solo determinar la cantidad de datos o la velocidad del flujo a través de un enlace, también es útil hacer análisis detallados del uso del ancho de banda para descubrir patrones de uso de la red, por ejemplo una universidad podría desear saber que porcentaje del ancho de banda esta siendo utilizado por streams de audio o video, a una empresa le gustaría saber cuanto tiempo pasan sus empleados en redes sociales, un analista desea saber cuales son los sitios web mas visitados en una red, etc. 

NOTA PARA EL PROFESOR: ayuda, no encontré ninguna cita que me ayudara a definir estos conceptos, sin embargo me parece que es importante incluir esto en el marco teórico.

\subsection{Disponibilidad}

Un servicio esta disponible para un cliente cuando dicho cliente puede comunicarse con el, análogamente un servicio no esta disponible para un cliente cuando no puede comunicarse con el, ya sea por un problema en el nodo final o en la red \cite{dahlin2003end}. 

Generalmente la disponibilidad se mide a través de la disponibilidad promedio, que es la fracción del tiempo  durante el cual un servicio esta disponible para un cliente promedio \cite{dahlin2003end}, sin embargo también se puede usar la disponibilidad continua, en este trabajo llamaremos actividad continua a un evento durante el cual un servicio está continuamente disponible para un cliente, y un inactividad continua a un evento durante el cual un servicio esta continuamente no disponible para un cliente.

Hemos definido la disponibilidad como un concepto meramente binario, en el que si un servicio es alcanzable entonces está disponible \cite{dahlin2003end} sin embargo hay ciertos escenarios en los que se puede considerar que un nodo alcanzable está fallando en ofrecer un servicio adecuadamente, por ejemplo cuando un servidor web está respondiendo a las peticiones con un código de estado 500, o cuando la latencia es tal que hace que una comunicación en tiempo real no sea posible. 

\subsection{Bufferbloat}

Bufferbloat es la existencia de buffers excesivamente grandes y generalmente llenos presentes en Internet \cite{gettys2011bufferbloat}; puede parecer contra-intuitivo ya que buffers mas grandes implican que menos paquetes serán desechados al llegar a un enrutador congestionado, pero mientras la cola en la interfaz del enrutador crece también lo hace el tiempo de espera del paquete y a la vez interfiere (o invalida) los algoritmos de control de congestión de los protocolos mas comunes en la capa de transporte \cite{gettys2011bufferbloat}.

El bufferbloat puede ser mitigado configurando apropiadamente el hardware disponible, sin embargo es difícil de diagnosticar y es confundido frecuentemente con congestión en la red.

Recientemente se ha comenzado a medir el blufferbloat como el tiempo adicional que toma enviar paquetes a través de un enlace congestionado, algunas pruebas disponibles en linea \cite{DSLReports}\cite{ThinkBroadband} intentan determinar este retraso haciendo mediciones constantes de latencia al mismo tiempo que inundan el enlace para determinar la forma en que esta varía durante la prueba.

\section{Big Data}

Debido a la rápida evolución en la capacidad de almacenamiento y procesamiento de los sistemas computaciones y la adopción de los mismos por parte de miles de millones de usuarios en Internet, así como la creciente de popularidad de objetos inteligentes (Internet de las Cosas), sensores, cámaras, micrófonos, lectores biométricos, lectores de radiofrecuencia, entre muchos otros, día a día se están produciendo datos de forma rápida y masiva, esta tendencia creciente en la generación de datos ha hecho evidente la necesidad de tener sistemas capaces de manipular estos datos para obtener información que no se hubiera hecho evidente usando otros métodos de análisis. 

Big Data se refiere la tendencia reciente de recolectar, almacenar y hacer análisis sobre cantidades masivas de datos, Big Data es un termino relativamente impreciso ya que no existe un convenio sobre la cantidad de datos a la que se refiere, pero usualmente el termino se relaciona con datos en el orden de los petabytes (10\textsuperscript{15} bytes) y exabytes (10\textsuperscript{18} bytes) \cite{barranco2012}. 

El aprovechamiento de este flujo de datos generalmente inmanejable por los sistemas previamente concebidos ha sido adoptado por muchos tipos de organizaciones, por ejemplo las redes sociales rutinariamente analizan a sus usuarios para descubrir sus gustos y preferencias y ajustar cuidadosamente la publicidad que estos ven, juegos en linea analizan a sus jugadores para entender que factores determinan su comportamiento y de esta manera optimizar finamente las experiencias que les ofrecen, un ejemplo conocido de uso de big data en el ámbito medico ha sido la exitosa predicción de transmisión de enfermedades como el dengue a partir de patrones de búsqueda en google\cite{GoogleFlu}, también existe preocupación sobre el uso del big data para violar la privacidad de usuarios de Internet por parte de organizaciones gubernamentales de seguridad y vigilancia que son capaces de conocer todo tipo de detalles personales como transacciones y compras, sitios web visitados, búsquedas realizadas, publicaciones en redes sociales, posición geográfica con el uso de GPS, etc.

\section{Visualización de datos}

La visualización de datos se refiere al aprovechamiento de elementos gráficos para representar información cuantitativa; cualquier conjunto de datos no tienen significado sin alguna manera de organizar y  presentar los descubrimientos relevantes que se encuentran potencialmente ocultos dentro de estos.

Los humanos podemos comprender los datos de mejor manera cuando son presentados a través de imágenes y elementos gráficos que leyendo números en tablas y columnas\cite{Pervasif}, una visualización apropiada de los datos permite de forma efectiva preguntar y responder las preguntas relevantes a una organización, por ejemplo en el marco de un sistema de monitoreo de redes preguntas como "¿donde están apareciendo los cuellos de botella?" "¿que factores afectan el rendimiento de un enlace?" o "¿cuales son los patrones de uso de los usuarios de la red?"

Hay una variedad de métodos apropiados para visualizar distintos conjuntos de datos, por ejemplo, los datos discretos se pueden observar a través de gráficas de barras, los gráficos de redes pueden comunicar la relación entre distintos entes, los mapas son efectivos para desplegar información geográfica, los mapas de calor permiten comparar el rendimiento de una variable a través del tiempo, etc, cada una de estas visualizaciones puede ser enriquecida a través del uso creativo de colores y formas para agregar nuevas dimensiones a los datos representados, por ejemplo, es posible combinar distintos conceptos para lograr visualizaciones aun mas poderosas como mapas de calor superpuestos en mapas de esta manera se pueden expresar datos de variable al mismo tiempo que se da una idea de su posición geográfica.

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{img/crimespotting}
\caption{Visualizacion de datos sobre delincuencia en el distrito de Columbia  Imagen tomada del
	sitio:: http://www.pervasif.com/index.php/news-a-event/capabilities/data-visualization}
\label{fig:crimespotting}
\end{figure}

En la figura \ref{fig:crimespotting} se puede observar como se usan distintos métodos para representar datos sobre crímenes como robo de vehículos, homicidios y asaltos con armas letales en un área del distrito de Columbia, un mapa es usado para mostrar la localización en que se ocurrieron los crímenes, en esta representación se puede observar rápidamente que zonas son mas propensas a cada tipo de crimen y obtener una idea de su frecuencia, a la izquierda se puede ver una gráfica de barras mostrando la cantidad de ocurrencias coloreadas por tipo de crimen y separados por día de la semana, de esta manera es posible no solo observar que crímenes son mas frecuentes sino que días y semanas son las peores. También se ofrecen herramientas para filtrar los crímenes por fecha, tipo de crimen y distrito, este tipo de herramientas de visualización de datos interactivas son cada vez mas populares en todo tipo de organizaciones ya que facilitan el análisis efectivo de sus datos.

\section{Computación en la nube}

La computación en la nube se refiere tanto a las aplicaciones desplegadas como servicios en Internet y el hardware y los sistemas computaciones en los centros de datos que proveen dichos servicios \cite{armbrust2010view}, a los servicios en si mismos se les ha dado el nombre de Software como Servicio (SaaS) y al hardware y software en los centros de datos es a lo que llamamos una nube. Cuando una nube se hace disponible para el publico en general a través de alguna forma de pago, se le llama una nube publica y el servicio que se esta vendiendo es Computación como Utilidad (Utility Computing), se le llama nube privada a los centros de datos internos de negocios u otras organizaciones pero que no pueden ser usados por el publico general, por lo tanto llamamos computación en la nube a la suma de SaaS y Computación como Utilidad sin incluir nubes privadas\cite{armbrust2010view}

La computación en la nube se caracteriza por ofrecer métodos de pago flexibles que permiten pagar solo por los recursos que se están utilizando (pay-as-you-go) y con una fina granularidad de modo que es lo mismo pagar mil procesadores una hora que un procesador por mil horas, esto permite a aplicaciones manejar cargas y escalas fluctuantes o patrones de uso específicos sin necesidad de tener hardware que esté ocioso durante largos periodos de tiempo. La nube ofrece a desarrolladores la ilusión de recursos computaciones ilimitados y disponibles a petición, eliminando la necesidad de planificar y aprovisionar equipos de hardware, y minimizar los riesgos relacionados con subestimar una aplicación que explota en popularidad o sobrestimar una aplicación que no llena las expectativas, en otras palabras no es necesario tener un gran capital de inversión inicial independientemente de la escala que resulte necesario manejar a corto o mediano plazo.

\subsection{Modelos de servicio en la nube}

Existen tres modelos de servicios en la nube que forman una "arquitectura orientada a servicios", estos son:

\subsubsection{Infraestructura como Servicio (IaaS)}

Infraestructura como Servicio a veces llamado Hardware como Servicio (HaaS) ofrece funciones básicas de almacenamiento y capacidad de computo como servicio ya sea a través de equipos de hardware físicos o de forma mas común como maquinas virtuales y una larga gama de imágenes de software disponible.

Esta capa abstrae al usuario de los detalles de infraestructura de los recursos de computo físico, localización, configuración, escala, seguridad, respaldo, mantenimiento, etc.

\subsubsection{Plataforma como Servicio (PaaS)}

Plataforma como servicio ofrece como servicio una plataforma para el desarrollo, ejecución y manejo de aplicaciones web, los recursos computacionales demandados por la aplicación son manejados automáticamente, de modo que la complejidad de manejar la infraestructura subyacente queda eliminada, esto permite reducir enormemente la complejidad necesaria para desplegar aplicaciones, que pueden pasar de la etapa de desarrollo y pruebas rápidamente a un entorno de producción con un esfuerzo mínimo. 

\subsubsection{Software como Servicio (SaaS)}

En el modelo de Software como servicio, los usuarios ganan acceso y hacen uso de aplicaciones de software, generalmente este tipo de software se paga bajo una subscripcion o por uso, este tipo de aplicaciones en la nube es conveniente y atractiva para los usuarios ya que estos no necesitan instalar software adicional en sus dispositivos sino que puede acceder a la aplicación desde navegadores web, esto permite que los usuarios puedan tener la misma experiencia en cualquier plataforma y reduce los costos operacionales.

\section{Herramientas usadas para el desarrollo del sistema}

A continuación se describen las herramientas usadas para el desarrollo del sistema de monitoreo de redes orientado a la recolección masiva de datos.

\subsection{Modelo Vista Controlador (MVC)}

El Modelo Vista Controlador es un patrón de diseño que divide la lógica de los datos y la presentación de forma claramente identificable y bien definida \cite{pantoja2004patron}.

Este patrón de diseño es especialmente popular en el marco de aplicaciones web ya que su abstracción permite escribir software altamente desacoplado y fácil de mantener y escalar.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{img/mvc}
	\caption{Ejemplo de la relación entre los componentes de una aplicación MVC  Imagen tomada del
		sitio: http://mind42.com}
	\label{fig:mvc}
\end{figure}


\subsubsection{Modelo} 

Según \cite{pantoja2004patron} \textit{''El modelo es un conjunto de clases que representan la información del mundo real que el sistema debe procesar, así por ejemplo un sistema de administración de datos climatologías tendrá un modelo que representará la temperatura, humedad ambiental, estado del tiempo esperado etc''}

Según la implementación de MVC el modelo puede dividirse en el modelo del dominio que es el modelo propiamente dicho, es decir una colección de clases que modelan la realidad relevante a la aplicación, y opcionalmente el modelo de la aplicación; este modelo tiene conocimiento de las vistas y es capaz de enviar notificaciones cuando ocurren cambios en el modelo. El modelo de la aplicación también es llamado coordinador de la aplicación \cite{pantoja2004patron} .

\subsubsection{Vista} 

La vista es la encargada de determinar que información contenida en el modelo mostrar al usuario y la presentación, por ejemplo si se está modelando una caldera es posible tener una vista que dibuje gráficamente el nivel de la caldera y un termómetro con su temperatura y otra vista que sencillamente muestre estas propiedades en una tabla. 

La vista pudiera cambiar cuando se actualiza el modelo del dominio a partir de notificaciones emitidas por el modelo de la aplicación, siguiendo con el ejemplo anterior de esta forma sería posible monitorear en tiempo real el estado de la caldera a partir de sensores que mantengan actualizado el modelo. 

\subsubsection{Controlador} 

El controlador es el encargado de dirigir el flujo de control de la aplicación a partir de mensajes externos, como datos introducidos por el usuario en el caso de una aplicación de escritorio o peticiones HTTP en el caso de aplicaciones web. A partir de estos estímulos, el controlador se encargará de invocar las vistas apropiadas, actualizar el modelo y hacer todas las acciones necesarias.

Distintas implementaciones del patrón MVC se toman la libertad de establecer la linea que separa el controlador y la vista de forma distinta, por ejemplo en algunas implementaciones el controlador se encarga tanto de actualizar el modelo y las vistas como de responder a los mensajes externos, es decir que el controlador es el encargado de ejecutar toda la lógica, y la vista meramente contiene la presentación de los datos, en otras implementaciones como veremos en la próxima sección la vista es la encarga tanto de seleccionar los datos que van a mostrarse así como de desplegar la presentación, esta ultima es una variación de MVC a veces llamado MTV (Modelo-Template-Vista)

\subsection{Django}

Django es un framework de desarrollo de aplicaciones web construido en python, en este trabajo usamos Django como el fundamento para Octopus Head. Django permite construir aplicaciones web rápidamente gracias a su filosofía de "baterias incluidas", es decir, que incluye una inmensa gama de características comunes a la mayoría de las aplicaciones web como validaciones de formularios, autenticación de usuarios, manejo de sesiones entre muchos otros; de esta manera el desarrollador puede concentrarse en escribir la lógica que es especifica a su aplicación y dejar que Django maneje los aspectos repetitivos y muchas veces tediosos de la pila de desarrollo web.

Django esta diseñado con una arquitectura MVC es decir que separa claramente la lógica, de los datos y la forma en que dichos datos son presentados al usuario, en el caso de Django la "vista" describe que datos son presentados al usuario y el "template" representa la forma en que los datos son presentados. 

Cuando Django recibe una petición esta pasa por un despachador de URLs (URL Dispatcher), cuya tarea es emparejar el URL con una vista y delegar a la vista el manejo de la petición. La vista contiene la lógica necesaria para atender la petición entrante, generalmente esto consiste en retirar o actualizar algunos datos del modelo, que a su vez se comunica con el manejador de base de datos, finalmente la vista combina los datos retirados de la base de datos, la petición y la sesión activa con una plantilla (template) para generar la respuesta que será devuelta, en la figura \ref{fig:django-arch} puede verse el ciclo de petición-respuesta tal como se ha descrito.

\begin{figure}[h!]
\centering
\includegraphics[width=0.5\linewidth]{img/dj-req-resp}
\caption{Ciclo de peticion-respuesta de Django}
\label{fig:django-arch}
\end{figure}

Las respuestas generadas por Django pueden ser tanto paginas HTML con CSS y Javascript pensadas para la interacción con el usuario así como respuestas en formato json o xml para la construcciones de APIs que pueden ser usados para la comunicación maquina-maquina, esto es especialmente útil cuando se desea desarrollar aplicaciones en otras plataformas como Android o iOS que compartan el mismo backend.

Django ha demostrado ser escalable y flexible, se sabe de instancias de Django atendiendo ráfagas de cincuenta mil peticiones por segundo, ademas es de código abierto, gratuito y cuenta con una enorme comunidad de colaboradores y amplia documentación. 

\subsection{Celery}

Celery es un sistema de procesamiento de tareas asíncrono, que permite tanto el encolamiento de tareas en tiempo real así como la planificación de tareas para ser ejecutadas mas tarde. Celery en realidad no implementa la mayoría de sus componentes, sino que define un protocolo de comunicación entre una serie de componentes (tambien llamados micro-servicios) que son: 

\begin{itemize}
	\item{Bróker de mensajería: el message broker es el encargado almacenar las tareas que deben ser ejecutadas, este consiste de una o mas colas de prioridad, de esta manera es posible controlar finamente que tareas deben ser ejecutadas con mayor urgencia, y por que ejecutores.}
	\item{Planificador: el planificador es el encargado de encolar tareas previamente planificadas para que sean ejecutadas en algún momento especifico, el planificador no puede asegurar que las tareas sean ejecutadas exactamente en el tiempo planificado ya que el tiempo de ejecución depende del tamaño de la cola y de las tareas que ya estén siendo ejecutadas por los ejecutores.}
	\item{Workers (Ejecutores): los ejecutores son los encargados de ejecutar las tareas; estos se subscriben a una o mas colas y consumen los mensajes según la prioridad establecida en la cola finalmente escriben los resultados obtenidos en un result backend}
	\item{Result Backend: sirve como un almacen donde se guardan los resultados de las tareas ejecutadas durante un periodo de tiempo dado, esto hace posible consultar los resultados obtenidos por un tarea}
\end{itemize}

Uno de los problemas comunes en el desarrollo de aplicaciones web es la ejecución de tareas largas o altamente bloqueantes que mantienen ocupado al servidor web durante periodos prolongados y peor aun mantienen al usuario final esperando, para evitar este escenario el servidor web debe tener una forma de delegar este tipo de tareas para ser ejecutadas después y responder inmediatamente.

Celery es usado comúnmente junto a Django y permite a una aplicación web escalar indefinidamente ya que solo hace falta aumentar el número de trabajadores disponibles que se pueden distribuir en tantas maquinas físicas (o maquinas virtuales en un servicio IaaS) como sea necesario. 

\subsection{Redis} \label{sub:redis}

Redis es un almacén de estructuras de datos en memoria que puede ser usado como base de datos, cache o bróker de mensajería; se caracteriza por su velocidad de respuesta ya que todos sus datos se mantienen en memoria principal y no invierte recursos en asegurar la persistencia de sus datos, evidentemente esto tiene como consecuencia que se pierden sus datos almacenados en caso de que ocurra cualquier falla inesperada. Redis puede ser usado como bróker de mensajería o como result backend por una aplicación Celery. 

\subsection{Bases de Datos}

Uno de los pilares fundamentales de casi toda aplicación moderna es tener un modo de almacenar datos de forma persistente en el tiempo así como consultarlos y actualizarlos de forma rápida, segura y resistente a fallas.

Según \cite{MysqlDev} una base de datos es una colección de datos estructurados. Puede ser cualquier cosa desde una simple lista de compras, una galería de fotos o las bastas cantidades de información en una red corporativa. Para agregar, acceder y procesar la data almacenada en una base de datos, se necesita un sistema manejador de base de datos. Ya que los computadores hacen un muy buen trabajo manejando grandes cantidades de datos, los sistemas manejadores de bases de datos juegan un papel central en la computación como utilidades independientes o partes de otras aplicaciones.

SQL por sus siglas en ingles "Structured Query Language" (lenguaje de consulta estructurado) es el lenguaje estandarizado mas común para acceder a bases de datos, SQL está definido por el Estándar ANSI/ISO SQL y ha ido evolucionando desde 1986 para convertirse en un estándar de facto en el mundo de la computación.  

\subsubsection{Mysql}

Mysql es un sistema manejador de bases de datos relacionales (RDBMS por sus siglas en ingles) de codigo abierto bajo la licencia GPL (GNU General Public License). Mysql se caracteriza por ser rápido, confiable, escalable y fácil de usar, es posible instalar Mysql tanto en una maquina junto a otras aplicaciones como servidores web o también instarlo en maquinas dedicadas para que use todo el poder disponible. Mysql posee características para ejecutarse en clusters de maquinas junto con un motor de replicacion para obtener una alta escalabilidad \cite{MysqlDev}.

\subsubsection{Mapeo Objeto-Relacional}

El Mapeo Objeto-Relacional (ORM por sus siglas en ingles) es un método para interactuar con bases de datos relaciones desde el paradigma de la programación orientada a objetos, de esta manera es posible aprovechar conceptos como herencia y polimorfismo.

Según \cite{ScottORM} la mayoría de las aplicaciones modernas usan lenguajes orientados a objetos como Java o C\# para construir aplicaciones y bases de datos estructuradas para almacenar datos, por lo tanto, es util tener una interfaz que transforme los datos entre estos tipos de incompatibles. 

El uso de un ORM simplifica enormemente el manejo de la estructura de datos subyacente ya que permite al programador manejar los datos a un mayor nivel de abstracción como si fueran objetos, sin necesidad de generar manualmente las consultas SQL, ademas esta capa de abstracción permite desacoplar el código de la aplicación de los detalles específicos de cada RDBMS.

\subsection{Json (JavaScript Object Notation)}

Json (JavaScript Object Notation) o notación de objectos javascript es un formato textual de intercambio y almacenamiento de datos no estructurados, json posee un formato que es fácil de leer para humanos y fácil de interpretar para maquinas y mas ligero que XML por lo que se ha popularizado para el desarrollo de APIs. 

Json soporta dos tipos de estructuras de datos:
\begin{enumerate}
	\item{Colecciones de pares nombre,valor comparable a un diccionario o tablashash.}
	\item{Listas ordenadas de valores, similar a las listas o vectores que existen en virtualmente cualquier lenguaje de programación }
\end{enumerate}

Un archivo en formato json puede estar formado de cualquiera de las estructuras de datos antes escritas o cualquier permutacion de dichas estructuras anidadas. 

Los tipos de datos soportados por json son:
\begin{itemize}
	\item{Number: numeros flotantes de doble presicion en formato Javascript}
	\item{String: cadenas de caracteres unicode encerradas en dobles comillas} 
	\item{Boolean: true o false}
	\item{Arreglo: secuencia de valores ordenados}
	\item{Objeto: colección no ordenada de pares nombre,valor}
	\item{null: nulo o vacío}
\end{itemize}

\subsection{Dropbox}

Dropbox es una plataforma de almacenamiento de datos en la nube de tipo PaaS y SaaS que permite compartir y sincronizar archivos entre un número arbitrario de clientes.

Dropbox es usado por aproximadamente 400 millones de personas y 100000 organizaciones\cite{Dropbox} y posee aplicaciones en Windows, Linux, Mac OS X, iOS, Android, Blackberry y web. 

Como todo servicio en la nube es atractivo para desarrolladores por ser robusto y confiable y es gratis hasta cierta cuota de almacenamiento a partir del cual el pago escala según la cantidad de almacenamiento usado.


\subsubsection{API de Dropbox}

Un API (Aplication Programming Interface) o interfaz de programación de aplicaciones, es una serie de métodos o funciones orientados a la comunicación maquina-maquina, en el caso de la computación en la nube un API conforma un servicio que permite desarrollar aplicaciones una plataforma (en este caso Dropbox).

El API de Dropbox permite realizar peticiones (como subir o descargar archivos, listar directorios o crear carpetas) sobre el espacio de almacenamiento de un usuario, el usuario debe previamente dar permiso a la aplicación para que esta pueda hacer cambios a su nombre, el usuario puede elegir denegar el acceso a la aplicación en todo momento y existen distintos tipos de esquemas de acceso donde una aplicación solo tiene acceso a un conjunto limitado de directorios dentro del espacio de almacenamiento del usuario.

El API de Dropbox impone ciertos límites de peticiones por usuario para impedir que una aplicación realice una cantidad excesiva de peticiones durante un cierto periodo de tiempo, sin embargo el limite se considera lo suficientemente alto como para no entorpecer la inmensa mayoría de los casos de uso.

\subsection{Diseño web adaptable}

Debido a la inmensa diversidad de dispositivos desplegados en el mercado y sus distintos tamaños y formas es imposible realizar manualmente diseños que puedan ajustarse a cada uno de ellos, anteriormente una solución popular a este problema era tener varias versiones con distintas resoluciones y elegir que versión mostrar a cada cliente, sin embargo esto ya no es necesario gracias a las nuevas herramientas disponibles en HTML5 CSS y Javascript que están ampliamente implementadas en navegadores modernos.

El diseño web adaptable o "Responsive Web Design" es la tendencia en el diseño de paginas web que se ajusten elásticamente a cualquier resolución, adaptando la forma en que se presentan sus elementos de forma "inteligente".

Las técnicas mas comunes para lograr esto es tener elementos que ocupen el mayor espacio horizontal posible en pantallas grandes y mientras el tamaño horizontal se reduce estos pasan a ocupar el espacio verticalmente; siempre ocupando el máximo del ancho disponible, evitando crear barras de desplazamiento horizontal que desorientan e incomodan a los usuarios. 

Otra heuristica en la creación de sitios web adaptables es escalar o esconder elementos gráficos decorativos o menús de navegación laterales, reducir el tamaño de margenes o incluso cambiar tipos de letras para que sean mas legibles en dispositivos móviles, mientras el tamaño del dispositivo es menor, cada pixel se vuelve mas precioso.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{img/responsive}
\caption{Ejemplo de diseño adaptable, se puede ver como los elementos se reagrupan, escalan o esconden para ajustarse al tamaño de la pantalla.}
\label{fig:responsive}
\end{figure}


El diseño web adaptable no solo facilita el desarrollo de sitios web ahorrando a los desarrolladores y diseñadores el costo de construir múltiples versiones de un mismo sitio web sino que ademas el sitio web ofrece una experiencia similar independientemente del dispositivo con el que se este visitando.

\subsection{Highcharts}

Highcharts es una biblioteca Javascript para dibujar gráficas en entornos HTML es gratis para proyectos no comerciales y de código abierto. Las gráficas generadas por highcharts aprovechan las características de HTML5 por lo que pueden soportar enormes conjuntos de datos sin afectar el rendimiento incluso en dispositivos móviles, son totalmente interactivas de manera que el usuario puede inspeccionar detalladamente el conjunto de datos y son dinámicas permitiendo actualizar la gráfica en tiempo real cuando se reciben nuevos datos.

Highcharts incluye una amplia gama de gráficas predefinidas que la hace ideal para todo tipo de visualización de datos como mapas de calor, splines, gráficas de área, barras, pie, mapas, entre muchos otros; cada una de ellas ofrece un gran control sobre la forma en que son presentadas de modo que es posible lograr casi cualquier resultado deseado.

Desde el punto de vista del programador es muy fácil de usar ya que solo requiere especificar un "objeto de configuración" y uno o mas arreglos conteniendo los datos a desplegar, es posible obtener distintas representaciones de los mismos datos solo cambiando el objeto de configuración. 

\subsection{Google Maps}

Google Maps es el servicio de mapas web de Google, ofrece distintos tipos de mapas, como mapas viales, mapas de relieve e incluso imágenes satelitales e imágenes de calles en tercera dimensión (llamado Google Street View)

Los mapas de Google Maps son totalmente dinámicos, permitiendo al usuario desplazarse, hacer zoom y cambiar el tipo de mapa a voluntad, Google Maps funciona dividendo el espacio mostrado en sectores que son descargados individualmente, de manera que cuando el usuario desplaza el mapa solo es necesario descargar los nuevos sectores desde los servidores de Google.

Google Maps es una de las herramientas mas populares para dibujar mapas web ya que ofrece un API gratuito y fácil de usar que permite enmarcar mapas en cualquier sitio web con solo algunas lineas, ademas los mapas de Google son de altisima calidad y se mantienen constantemente actualizados. 

\subsection{Geo-localizacion IP}

La geo-localizacion IP consiste en asignar a un IP la localizacion geográfica de la maquina anfitriona correspondiente\cite{poese2011ip}. 

Existen dos paradigmas principales para aproximar la localización geográfica de una dirección IP: activo y pasivo; las técnicas activas de localización se basan en mediciones de retraso y en muchos casos proveen resultados precisos\cite{poese2011ip}, el paradigma pasivo consiste del uso de bases de datos que contienen rangos de direcciones ips a los que se les llaman bloques o prefijos relacionados a una localización geográfica especifica, sin embargo su precisión puede estar sujeta a errores substanciales. En ambos casos es imposible conocer la localización exacta asociada a una dirección IP sin la colaboración activa de los anfitriones finales, sin embargo es posible hacer buenas aproximaciones en algunos a nivel de ciudades o países.

Ya que conocer la localización de sus clientes a partir de su dirección ip es útil para muchos servicios (por ejemplo, para conducir anuncios localizados) existe una gran variedad de soluciones de geolocalizacion tanto gratuitas como de pago.

\subsection{Ajax}

AJAX (Asynchronous JavaScript And XML) es una técnica para construir sitios web interactivos a través de peticiones asíncronas con Javascript que mantienen comunicación con el servidor web para mantener el estado del cliente actualizado sin necesidad de que el usuario tenga que refrescar la pagina o realizar consultas adicionales, de esta manera el usuario tiene una experiencia similar a la que tendría con aplicaciones de escritorio. 

A pesar de que el nombre AJAX sugiera el uso XML como lenguaje para la transferencia de datos entre el cliente y el servidor, se puede usar cualquier formato como texto plano, HTML y JSON

\subsection{APScheduler}

APScheduler (Advanced Python Scheduler) es una biblioteca python para retrasar la ejecución de rutinas a un instante dado en el futuro ya sea como eventos de una sola vez o de forma recurrente\cite{APScheduler}, esta biblioteca provee las herramientas para construir cualquier esquema de planificación que se desee su arquitectura consta de componentes altamente desacoplados que pueden ser mezclados, combinados o incluso extendidos para ofrecer nuevas funcionalides.

\subsubsection{Triggers (gatillos)}

Los triggers (gatillos) son los encargados de determinar el momento de la próxima ejecución de una tarea, APScheduler incluye tres gatillos predefinidos: DateTrigger que ejecuta tareas dada una fecha y hora, IntervalTrigger que ejecuta tareas de forma recurrente dado un intervalo fijo y CronTrigger que ejecuta tareas de forma similar a crontab del sistema UNIX.

\subsubsection{Job Stores (almacenes de tareas)}

Job Stores o almacenes de tareas determinan la forma en que las tareas serán alojadas por el planificador, por defecto las tareas se guardan en memoria, sin embargo también es posible guardar las tareas en almacenes persistentes como bases de datos SQL o mongo.

\subsubsection{Executors (ejecutores)}

Los ejecutores son los encargados de ejecutar tareas y posteriormente informar al planificador del estado de la tarea. El ejecutor por defecto consta de un arreglo de hilos (thread pool) pre-instanciados listos para aceptar tareas, sin embargo si se tienen tareas de uso intensivo de CPU, esta disponible un ejecutor basado en procesos que puede aprovechar mejor las características de procesadores multinúcleos \cite{APScheduler}.

\subsubsection{Shedulers (Planificadores)}

Los planificadores son los que unen todos los elementos mencionados anteriores y son los encargados de gestionar las tareas, es decir que delegan a los ejecutores la ejecución de las tareas en el tiempo adecuado y duerme esperando la ocurrencia de eventos que requieran su atención.

APScheduler incluye dos planificadores predefinidos: BackgroundScheduler que se ejecuta instanciando un hilo en segundo plano y permite que el flujo del programa continúe, útil cuando se desea realizar otras funciones o como agregar o modificar tareas después de que el planificador se ha inicializado y BlockingScheduler que se ejecuta en el mismo hilo de ejecución bloqueando el flujo del programa indefinidamente.

\subsection{Ping} \label{sub:ping}

Ping es un programa utilitario incluido en todos los sistemas basados en UNIX y Windows que comprueba la presencia y tiempo de respuesta de un host en una red IP. Ping utiliza el Protocolo de Mensajes de Control de Internet (ICMP) para enviar un paquete de solicitud ICMP (ICMP Echo Request) y espera el mensaje de respuesta del host remoto (ICMP Echo Reply); calculando la diferencia de tiempo entre el envío y la recepción se puede calcular la latencia de la red, ping también incluye funciones para enviar paquetes en ráfaga útil cuando se desea medir la perdida de paquetes.

Ya que históricamente ping se ha usado por atacantes para determinar la presencia de equipos en una red o realizar ataques de denegación de servicio (ping flood) muchos enrutadores y firewalls bloquean estos mensajes como medida de seguridad, aunado a esto ya que ping utiliza ICMP que es un protocolo de capa de red, este no es capaz de alcanzar equipos detrás de un NAT; a pesar de esto, ping ha demostrado ser una herramienta vital en el diagnostico y monitoreo de redes IP.

\subsection{Traceroute}

Traceroute (tambien llamado Tracert en sistemas Windows) es un programa utilitario de diagnostico que permite conocer los hosts que visita un paquete durante su transito por una red.

Al igual que Ping, Traceroute utiliza el protocolo ICMP pero envía paquetes con un valor de "Time to Live" (TTL) incremental, cada vez que un nodo de la red recibe un paquete decrementa su valor de TTL y si este llega a cero lo descarta y envía de vuelta al host emisor un mensaje de control indicando que el TTL llegó a 0, de esta manera Traceroute puede generar una lista de los nodos visitados y el valor de RTT para cada uno de ellos.

Un análisis cuidadoso de la salida de Traceroute puede ayudar a diagnosticar numerosos problemas en una red como ineficiencias en el enrutamiento, presencia de enrutadores congestionados, cuellos de botella, comportamientos inesperados, etc. 

\subsection{Iperf}

Iperf es una herramienta que permite medir el rendimiento (throughput) entre un par de nodos en un red. Al igual que muchas otras pruebas para medir velocidad de transferencia, Iperf funciona con una arquitectura cliente-servidor, donde el cliente genera un flujo de datos hacia el servidor y mide la velocidad obtenida, también es posible ejecutar una prueba "en reversa" donde es el servidor el que genera el flujo de datos.

Iperf puede ejecutar pruebas utilizando TCP o UDP, sin embargo existen diferencias entre ellos:

\begin{itemize}
		\item{Ya que UDP a diferencia de TCP no implementa ningún algoritmo de control de congestión se podría obtener un rendimiento ligeramente superior con este protocolo *Nota para el profesor: yo se que esto es "verdad" pero me gustaría poder sustentarlo un poco mejor o incluir una cita}
		\item{Con UDP se puede obtener una estadística de la perdida de paquetes durante la prueba}
		\item{Con UDP es el servidor el que totaliza los resultados, ya que el cliente no tiene manera de saber que datagramas se han recibido.}
\end{itemize}

Para obtener una buena medición del rendimiento del enlace hay que ajustar los parámetros de la prueba cuidadosamente, por ejemplo, es posible ajustar la cantidad de datos que se van a transferir durante la prueba, elegir una cantidad muy pequeña podría resultar en que no sea suficiente para saturar el enlace, mientras tanto elegir una cantidad demasiado grande podría resultar en una prueba innecesariamente larga, en ambos casos el valor del rendimiento obtenido no reflejará la realidad, también hay que tomar en cuenta que es difícil obtener una lectura exacta del rendimiento del enlace ya que podrían existir otros flujos en la red que afecten el resultado de la prueba. 

\chapter{Monitor de Red "Tentacle Monitor"}

Tentacle Monitor es un monitor de red ligero, diseñado para ajustarse a las limitaciones de sistemas de bajo costo y con la intensión de ser desplegado en las redes que se desea monitorear y ser dejado desatendido durante periodos arbitrarios de tiempo.

Tentacle Monitor ejecuta pruebas periódicas siguiendo un plan de monitoreo definido por el usuario con el objetivo recoger datos sobre las métricas relevantes a la red a monitorear, los resultados de las pruebas son guardados temporalmente en la memoria del dispositivo y se suben a la nube regularmente, la frecuencia en que se suben los datos a la nube depende de la cantidad de memoria disponible en el dispositivo, la cantidad de datos generados por el monitoreo y el ancho de banda disponible.

Uno de los objetivos principales de Tentacle Monitor es ejecutar las pruebas en el momento preciso dado por el plan de monitoreo, ya que el posterior análisis de los datos por parte de Octopus Head exige que las muestras se tomen con un patrón regular y conocido, para esto, un planificador que asegura la ejecución precisa de las pruebas es central en la arquitectura del monitor. Como ya se mencionó, el comportamiento del monitor viene dado por un plan de monitoreo, este es definido por el usuario en Octopus Head, toda la comunicación entre Tentacle Monitor y Octopus Head se realiza a través de la nube, Octopus Head transfiere el plan de monitoreo a través de archivos a modo de mensajes y los guarda en una carpeta a modo de buzón; Tentacle Monitor mantiene una conexión con la nube para ser notificado de cambios en dicha carpeta con baja latencia de esta manera se pueden leer los mensajes rápidamente y tomar las acciones necesarias, como incluir nuevas pruebas, replanificar pruebas, cambiar los parámetros de ejecución, o incluir nuevos enlaces a monitorear.

\section{Diseño del Monitor}

El diseño del monitor esta sujeto a los siguientes baremos: 

\begin{itemize}
	\item{\textbf{Estabilidad} ya que el monitor podría dejarse desatendido es esencial que sea estable, si el monitor no se está ejecutando el usuario no obtendrá los resultados esperados en la aplicación web.}
	\item{\textbf{Flexibilidad} el monitor debe ser capaz de cargar nuevas pruebas en tiempo de ejecución, esto es especialmente importante ya que no desea interrumpir otras pruebas que se estén ejecutando.}
	\item{\textbf{Planificación precisa} es importante que las pruebas se ejecuten en el momento adecuado, siguiendo de manera fiel el plan de monitoreo.}
	\item{\textbf{Ejecutable en equipos de bajo costo} el monitor debe incluir el código mínimo para su funcionamiento, tener un uso eficiente de memoria y evitar desbordar la memoria secundaria del host.}
	\item{\textbf{Configuración remota} el monitor debe incluir algún protocolo para actualizar su plan de monitoreo a partir de cambios hechos en la aplicación web.}
	\item{\textbf{Bitácora} ya que el monitor se ejecuta como un proceso daemon, se desea tener una bitácora donde se puedan leer mensajes sobre los eventos relevantes durante la ejecución.}
\end{itemize}

\subsection{Arquitectura}

Como se puede observar en la figura \ref{fig:tentacle-components.png}, Tentacle Monitor tiene una arquitectura basada en componentes altamente desacoplados con responsabilidades bien delimitadas para facilitar el desarrollo de la aplicación; cada uno de estos componentes puede ser reemplazado fácilmente siempre y cuando la interfaz entre ellos se mantenga intacta.

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{img/tentacle-components.png}
	\caption{Diagrama de Componentes Octopus Tentacle}
	\label{fig:tentacle-components.png}
\end{figure} 

\subsection{Diagrama de actividades}

La ejecución del monitor comienza en el cliente, el cliente es el encargado de instanciar el proceso daemon y lo hace a través del método bien conocido de doble fork. Para asegurarse de no ejecutar múltiples instancias del monitor se revisa un archivo .pid, si el archivo existe significa que el monitor se está ejecutando y el cliente informa del error al usuario. 

Después de que el proceso esta daemonizado comienza la fase de inicializacion, para esto se crea el planificador y se cargan las tareas del jobstore, importando el codigo de las pruebas a ejecutar. A este punto las pruebas están planificadas tentativamente y cargadas en memoria pero solo serán ejecutadas después de que se inicie el planificador.

Al iniciar el planificador este pasa a ejecutarse como un subproceso y se encarga de iniciar las tareas en el momento preciso. Cuando el planificador inicia una tarea se la pasa al ejecutor en este caso un grupo de subprocesos previamente inicializados, cuando un subproceso termina de ejecutar una tarea informa al planificador, esto con la finalidad de implementar políticas de concurrencia de tareas.

Mientras tanto, el hilo principal se conecta a la nube usando el API de Dropbox que posee un método para notificar a los clientes sobre cambios a una carpeta en tiempo real y con baja latencia, el método consiste en abrir una conexión HTTP con un alto valor de timeout (entre 30 y 120 segundos), si ocurre un cambio en la carpeta, el servidor de Dropbox responde de inmediato indicando que ocurrieron cambios y el monitor procederá a manejar este evento (descargando los archivos nuevos y aplicando los cambios al plan de monitoreo), en caso contrario, Dropbox responde indicando que no ocurrieron cambios y el monitor reinicia la conexión. 

Los eventos relevantes al monitor tentacle son los siguientes: (1) una prueba se ha agrega al plan de monitoreo y debe cargarse a memoria y planificarse (2) una prueba se ha eliminado y debe ser eliminada del plan de monitoreo (3) el intervalo entre pruebas de una prueba ha cambiado y debe replanificarse la próxima ejecución (4) los parámetros de una prueba han cambiado (5) se ha agregado un nuevo enlace a monitorear (6) se ha eliminado un enlace monitoreado.

El monitor solo puede detenerse a través de una señal del sistema operativo (SIGTERM), el cliente utiliza el archivo pid para determinar el id del proceso y enviar la señal. El manejador de excepciones del monitor entonces inicia una secuencia de apagado, deteniendo las pruebas, apagando el planificador y desbloqueado el archivo .pid.

Esta secuencia de actividades puede verse en la figura \ref{fig:tentacle-activity}.

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{img/tentacle-activity}
\caption{Diagram de actividades de Tentacle}
\label{fig:tentacle-activity}
\end{figure}


\section{Componentes}

\subsection{Cliente}

El cliente de Octopus Tentacle es el programa encargado de iniciar o detener la ejecución del monitor en modo daemon y funge como interfaz entre el usuario y monitor.

Se puede invocar el cliente con los siguientes comandos:

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}

\begin{table}[h!]
	\centering
	\label{my-label}
	\begin{tabular}{p{2cm}p{13cm}}
		\rowcolor{light-gray} Comando & Descripción \\ 
		\hline start & Inicia el monitor como un proceso daemon, falla si el archivo .pid ya existe (el monitor se esta ejecutando) \\ 
		\hline stop & Detiene el monitor enviando la señal SIGTERM al proceso daemon, falla si el archivo pid no existe (el monitor no se esta ejecutando) \\  
		\hline restart & Detiene e inicia el monitor \\ 
		\hline jobs & Muestra las tareas pendientes en el planificador (plan de monitoreo) \\ 
		\hline 
	\end{tabular} 
	\caption{Comandos del cliente Octopus Tentacle}
\end{table}

Los comandos start y restart se pueden invocar con la opción --no-daemon para iniciar el monitor en modo consola (sin daemonizar) 

\subsection{Hilo Principal}

El hilo principal de ejecución es el punto de partida desde el momento en que el proceso ya se ha convertido en un daemon, se encarga de inicializar el planificador el cual a su vez pasa a ejecutarse en segundo plano, luego, su tarea consiste en mantener el plan de monitoreo al día a partir de los cambios que se hagan en Octopus Head.

El hilo principal mantiene una conexión constante con el servidor de Dropbox para ser notificado de cambios en el plan de monitoreo, si hay cambios, este llama los métodos para leer los archivos y a partir de ellos hacer cambios en plan de monitoreo, como eliminar pruebas o agregar nuevos enlaces monitoreados.

\subsection{Planificador}

Para la implementación del planificador se hizo uso de APScheduler, una biblioteca que permite retrasar la ejecución de código python; el planificador se puede ejecutar como un subproceso de modo que es posible agregar, eliminar y re-planificar tareas en cualquier momento desde el hilo principal de la aplicación. 

APScheduler consiste de un conjunto de componentes configurables que se pueden extender o re-usar para obtener cualquier comportamiento deseado, a continuación se explica su funcionamiento y como se usaron en el marco de esta aplicación.

\subsubsection{Triggers (Gatillos)}

Los triggers contienen la lógica para determinar en que momento se debe ejecutar una tarea, la biblioteca incluye varios triggers predefinidos, de los cuales dos se han usado para el desarrollo de esta aplicación: 

\begin{itemize}
	\item{Interval Trigger: ejecuta pruebas en intervalos regulares, opcionalmente se pueden suministrar fechas finales e iniciales de modo que las pruebas solo se ejecuten durante un periodo especifico}
	\item{Date Trigger: ejecuta la prueba en una fecha especifica dada, una sola vez, útil para desplegar pruebas que usen muchos recursos de red como benchmarks de ancho de banda o capturas de tráfico de la red.}
\end{itemize}

\subsubsection{Executors (Ejecutores)}

El ejecutor es el ente encargado de llevar a cabo la ejecución de las tareas, en nuestro caso se ha hecho uso de un grupo de subprocesos (thread pool), la cantidad de hilos en el grupo esta dado por el numero de pruebas que estaremos ejecutando de modo que siempre se tenga al menos un hilo disponible cuando se inicia una prueba. 

\subsubsection{Almacén de tareas (Job store)}

El almacén de tareas guarda las tareas planificadas, el comportamiento por defecto es guardar las tareas en memoria, pero existen distintos tipos de almacenes como redis (ver sección \ref{sub:redis}) y bases de datos; hemos usado el SQLAlchemy job store que permite guardar tareas en una base de datos ligera como sqlite y así asegurar la persistencia de los datos de la aplicación.

\subsection{Almacenamiento Compartido}

El almacenamiento compartido se encarga de alojar los resultados de las pruebas en archivos de trazas, por cada prueba que se esté ejecutando se crea una carpeta donde se alojan sus respectivos archivos.

Para mantener el numero de archivos en el almacenamiento compartido razonablemente pequeño se crea para cada enlace un archivo por hora y todas las trazas que se generen en ese periodo se anexan al archivo correspondiente; el costo de alojar archivos en la nube no depende del numero de archivos sino del espacio total de disco en uso, ya que existe un limite de peticiones diarias por usuario debemos intentar minimizar la cantidad de peticiones que realizamos a Dropbox. Este tema se explicará a profundidad en la sección \ref{fig:sub:sincronizacion}.

\section{Pruebas Implementadas}

Gracias a la arquitectura de Tentacle, implementar una prueba es tan sencillo como crear un paquete e implementar la función "run" en el archivo init.py, todas las pruebas implementadas hasta ahora comparten una flujo de ejecución similar:
\begin{enumerate}
	\item{Se lee el archivo de configuración}
	\item{Se obtienen los enlaces a monitorear y los parámetros globales}
	\item{Se ejecuta la prueba por cada enlace monitoreado (ya sea en paralelo o en secuencia).}
	\item{Se ejecuta un comando externo externo como ping o traceroute o se usa una biblioteca python para evaluar alguna métrica del enlace.}
	\item{(opcional) si se ejecuta un comando externo se hace un parsing para extraer los resultados relevantes de la salida del programa}
	\item{Se guardan los resultados en un archivo de trazas; generalmente el resultado de una prueba está representado por una linea en archivo de trazas, sin embargo el desarrollador tiene libertad total sobre el formato que utilice para generar archivos de trazas}
\end{enumerate}

Durante el desarrollo de este proyecto se han implementado las siguientes pruebas:

\subsection{Ping}

Esta prueba hace uso del comando ping para obtener datos de la latencia en un enlace, como ya se menciono en la sección \ref{sub:ping} ping viene incluido en todas las distribuciones de linux por lo que no es necesario instalar ninguna dependencia o programa externo.

La prueba consiste en ejecutar el comando ping para cada uno de los enlaces monitoreados, ejecutamos el comando con la opción -D para que ping imprima cada resultado de latencia con una marca de tiempo entre corchetes, un ejemplo de la salida de ping se puede ver en la figura \ref{fig:ping-out}. 

Es muy sencillo extraer los datos relevantes de la salida de ping, para esto recorremos la salida descartando las lineas que no comiencen con el carácter '[', separamos la salida en palabras, la palabra en la posición 0 corresponde a la marca de tiempo, luego buscamos las palabras que comiencen por "icmp\_seq o icmp\_req y time" para obtener numero de secuencia icmp y tiempo de ida y vuelta respectivamente.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{img/ping-out}
	\caption{Ping output}
	\label{fig:ping-out}
\end{figure}

Independientemente del número de sondas que se envíen elegiremos solo un resultado de latencia por prueba (la mediana), si para una prueba no se obtiene ninguna respuesta entonces guardamos una traza con rtt=-1, indicando que el enlace está inactivo o el nodo está rechazando el protocolo.

\begin{table}[h]
	\centering
	\label{table:ping-parameters}
	\begin{tabular}{rp{2cm}p{9cm}}
		\rowcolor{light-gray} 
		Parametro              &  Tipo & Descripcion                                                                \\ \hline
		Numero de sondas       & Entero                      & Número de sondas icmp a enviar.                                            \\ \hline
		Timeout                & Float                       & Tiempo a esperar por una respuesta antes de asumir una sonda como perdida. \\ \hline
		Intervalo entre sondas & Float                       & Tiempo entre el envío de cada sonda individual.                           
	\end{tabular}
		\caption{Parametros de la prueba ping}
\end{table}

\subsection{Httping}

Esta prueba usa el protocolo HTTP para hacer un HEAD Request y obtener el tiempo de respuesta y código de estatus HTTP, a diferencia de la prueba con ping esta no ejecuta un comando externo sino que llama a una función de la biblioteca 'requests' que hace la petición directamente por lo que no es necesario ningún tipo de parsing. 

La tabla \ref{table:httping-parameters} muestra los parámetros de la prueba httping,

\begin{table}[h!]
	\centering
	\label{table:httping-parameters}
	\begin{tabular}{rp{2cm}p{9cm}}
		\rowcolor{light-gray} 
		Parametro              &  Tipo & Descripcion                                                                \\ \hline
		Timeout       & Float                      & Tiempo a esperar por una respuesta                                        \\ \hline
		Path                & String                       & Cadena de caracteres que se adjunta al ip o nombre de dominio del enlace, especialmente útil para probar servicios específicos de una aplicación o servicio web.. \\ \hline
		Port & Entero                       & Espeficia el puerto al que se envía la peticion HTTP.                           
	\end{tabular}
	\caption{Parametros de la prueba httping}
\end{table}

Esta prueba es útil para monitorear todo tipo de servidores web y posee la ventaja sobre ping de utilizar un protocolo de capa aplicación por lo que da una idea mas precisa de la experiencia del usuario al visitar dicho servicio; a diferencia de ping, el resultado obtenido no solo es la latencia de la red, sino la suma de la latencia de la red y el tiempo de respuesta del servidor, que puede estar sujeto, por ejemplo, al nivel de carga que esté manejando dicho servicio, o a la petición especifica que se esté realizando.

\subsection{Traceroute}

Esta prueba ejecuta el comando traceroute para obtener la ruta entre un par de nodos a través de una red ip, llamamos ruta a una secuencia de saltos (hops) que hace un paquete al atravesar un enrutador. 

El comando traceroute imprime la ruta como una lista ordenada donde cada linea representa un salto, con su dirección ip, nombre de dominio y latencia, dependiendo del numero de sondas que se estén enviando por salto pueden existir casos en que se obtenga respuesta de mas de una dirección ip, este comportamiento se puede ver en la figura \ref{fig:traceroute-out} en el salto 9 se observa que obtenemos una respuesta de la dirección ip 154.54.31.230 y dos de 154.54.47.154 

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{img/traceroute-out-white.png}
	\caption{Salida del comando traceroute}
	\label{fig:traceroute-out}
\end{figure}


A partir de la salida de traceroute se debe obtener una estructura de datos que facilite el análisis de la ruta, para esto se usó el modulo tracerouteparser.py\footnote{tracerouteparser.py es cortesia del proyecto Netalyzr: http://netalyzr.icsi.berkeley.edu}, que extrae la información de la cabecera (ip destino y nombre de dominio), asi como una lista de hops (saltos), cada hop es a su vez una lista de probes (sondas), cada sonda tiene dirección ip, nombre de dominio, rtt y anotaciones; ya que el ip destino es conocido, solo se guarda en el archivo de trazas la lista de saltos en formato json. 

El formato esta compuesto de la siguiente manera:

\lstset{
	numbers=left,
	stepnumber=1,    
	firstnumber=1,
	numberfirstline=true,
	numberstyle=\tiny,
	basicstyle =\small
}

\begin{lstlisting}][h,frame=single]
[
	[
		{
			"anno": anno_1,
			"rtt": rtt_1,
			"ipaddr": ipaddr_1,
			"name": name_1
		},
		{
			"anno":  anno_2,
			"rtt": rtt_2,
			"ipaddr": ipaddr_2,
			"name": name_2
		},
		...
	],
	...
]
\end{lstlisting}

Cada vez que se realiza una prueba con traceroute se anexa al archivo de trazas una entrada con la marca de tiempo de inicio de la prueba, un carácter de separación y luego una cadena en el formato json antes mostrado. 

Las parámetros de esta prueba son los siguientes:

\begin{table}[h]
	\centering
	\begin{tabular}{lll}
		\rowcolor[HTML]{C0C0C0} 
		Parametro        & {\color[HTML]{333333} Tipo} & Descripcion                                                           \\ \hline
		Numero de sondas & Entero                      & Número de sondas a enviar por cada valor de TTL.                      \\ \hline
		TTL Maximo       & Entero                      & Numero maximo de saltos antes de asumir que el nodo no es alcanzable. \\ \hline
	\end{tabular}
		\caption{Parametros de la prueba con traceroute}
		\label{tab:traceroute-params}
\end{table}

\subsection{Throughput con Iperf}

La prueba de throughput con iperf mide el ancho de banda entre un par de nodos usando el programa Iperf, como se pudo ver en las pruebas anteriores, siempre es necesario que el equipo destino (Tentacle Probe Destination) ofrezca algún tipo de respuesta ya sea en forma de ICMP Echo Reply o HTTP Response, en estos casos no necesariamente hace falta instalar o configurar el equipo destino pues estos ya implementan dichos servicios, sin embargo en el caso de Iperf el usuario que realiza el monitoreo debe asegurarse de mantener una instancia de Iperf en modo servidor para realizar las pruebas, en otras palabras el usuario debe tener acceso o contar con la colaboración explicita de los puntos finales a monitorear.

\begin{table}[h]
	\centering
	\begin{tabular}{lll}
		\rowcolor[HTML]{C0C0C0} 
		Parametro        & {\color[HTML]{333333} Tipo} & Descripcion                                                           \\ \hline
		Probar este enlace & Booleano                      & Determina si se debe o no ejecutar la prueba para un enlace especifico.                      \\ \hline
		Tiempo de transmisión       & Entero                      & Numero de segundos para transmitir datos durante la prueba. \\ \hline
		Bytes a enviar      & String                      & Cantidad de bytes a enviar durante la prueba, se puede especificar si el numero es en bytes o megabytes usando las letras B o M respectivamente, este parámetro se ignora si se establece el parametro anterior.. \\ \hline
		Numero de flujos       & Entero                      & Numero de flujos TCP simultáneos a usar durante la prueba. \\ \hline
		Puerto       & Entero                      & Especifica el puerto en que el servidor está escuchando en el TPS. \\ \hline
	\end{tabular}
	\caption{Parametros de la prueba con iperf}
	\label{tab:traceroute-params}
\end{table}

\section{Casos de uso}

Ya que el monitor de red Tentacle funciona de forma automatizada y todas las acciones de configuración y visualización de los datos recolectados por el se realizan en la aplicación web, solo se tienen cuatro casos de uso para el monitor.

\begin{table}[H]
	\caption{Caso de uso  Iniciar monitor}
	\begin{center}
		\begin{tabular}{r|p{2cm}p{8cm}}
			\textbf{\textit{TM-01}} & \multicolumn{2}{l}{\textit{Iniciar monitor}}\\
			\hline
			% Linea de descripción 
			\textbf{\textit{Descripción}} & \multicolumn{2}{p{10cm}}{El usuario desea iniciar el monitor de red tentacle.}\\
			% Linea de Secuencia normal
			\multirow{2}{*}{\textbf{\textit{Secuencia normal}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 1 & El usuario invoca el cliente con el comando "start". \\
			& 2 & El cliente crea el proceso daemon y retorna. \\
			% Linea de Secuencia excepciones
			\multirow{2}{*}{\textbf{\textit{Excepciones}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 3 & Si el archivo pid existe entonces el cliente muestra un mensaje de error indicando que el monitor ya se esta ejecutando. \\
		\end{tabular}
	\end{center}
\end{table}


\begin{table}[H]
	\caption{Caso de uso  Detener monitor}
	\begin{center}
		\begin{tabular}{r|p{2cm}p{8cm}}
			\textbf{\textit{TM-02}} & \multicolumn{2}{l}{\textit{Detener monitor}}\\
			\hline
			% Linea de descripción 
			\textbf{\textit{Descripción}} & \multicolumn{2}{p{10cm}}{El usuario desea detener el monitor que se esta ejecutando en modo daemon.}\\
			% Linea de Secuencia normal
			\multirow{2}{*}{\textbf{\textit{Secuencia normal}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 1 & El usuario invoca el cliente con el comando "stop". \\
			& 2 & El cliente abre el archivo pid y envía la señal SIGTERM al proceso daemon. \\
			& 3 & El monitor maneja la excepción deteniendo su ejecución. \\
			% Linea de Secuencia excepciones
			\multirow{3}{*}{\textbf{\textit{Excepciones}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 4 & Si el archivo pid no existe, el cliente informa al usuario que el monitor no se esta ejecutando. \\
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[H]
	\caption{Caso de uso  Reiniciar monitor}
	\begin{center}
		\begin{tabular}{r|p{2cm}p{8cm}}
			\textbf{\textit{TM-03}} & \multicolumn{2}{l}{\textit{Reiniciar monitor}}\\
			\hline
			% Linea de descripción 
			\textbf{\textit{Descripción}} & \multicolumn{2}{p{10cm}}{El usuario desea reiniciar el monitor que se esta ejecutando en modo daemon.}\\
			% Linea de Secuencia normal
			\multirow{2}{*}{\textbf{\textit{Secuencia normal}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 1 & El usuario invoca el cliente con el comando "restart". \\
			& 2 & El cliente abre el archivo pid y envía la señal SIGTERM al proceso daemon. \\
			& 3 & El monitor maneja la excepción deteniendo su ejecución. \\
			& 4 & El cliente crea el proceso daemon y retorna. \\
			% Linea de Secuencia excepciones
			\multirow{3}{*}{\textbf{\textit{Excepciones}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 5 & Si el archivo pid no existe, el cliente informa al usuario que el monitor no se esta ejecutando. \\
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[H]
	\caption{Caso de uso  Ver Plan de Monitoreo}
	\begin{center}
		\begin{tabular}{r|p{2cm}p{8cm}}
			\textbf{\textit{TM-04}} & \multicolumn{2}{l}{\textit{Ver Plan de Monitoreo}}\\
			\hline
			% Linea de descripción 
			\textbf{\textit{Descripción}} & \multicolumn{2}{p{10cm}}{El usuario desea ver el plan de ejecución del monitor.}\\
			% Linea de Secuencia normal
			\multirow{2}{*}{\textbf{\textit{Secuencia normal}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 1 & El usuario invoca el cliente con el comando "jobs". \\
			& 2 & El cliente abre la base de datos y retira la información. \\
			& 3 & El cliente muestra por pantalla las tareas planificadas y los enlaces monitoreados y retorna. \\
			% Linea de Secuencia excepciones
			\multirow{3}{*}{\textbf{\textit{Excepciones}}} & \cellcolor{light-gray}\textbf{Paso} & \cellcolor{light-gray}\textbf{Acción} \\
			& 5 & Si la base de datos no se ha creado muestra una lista vacía. \\
		\end{tabular}
	\end{center}
\end{table}

\chapter{Aplicación Web "Optopus Head"}

La aplicación web "Octopus Head" hace las veces de interfaz entre el usuario final y sus monitores de red, ademas es el encargado de recolectar los datos obtenidos del monitoreo y crear poderosas visualizaciones interactivas a partir de ellos, mientras los monitores realizan la tarea relativamente sencilla de recolectar datos de las redes a monitorear en Octopus Head se define el plan de monitoreo y se ejecutan las tareas pesadas de análisis de los datos recolectados para computar periodos de actividad continua, mapas de calor, horas y días activos, etc.

\section{Diseño del sistema}

Para el desarrollo de esta aplicación web se usó el Framework de desarrollo web Django que implementa un patrón MVC, ya que nuestra aplicación web se encargará de manejar tareas computacionalmente intensas, o de largo tiempo de ejecución, Django se integró con el sistema de procesamiento de tareas distribuido Celery, esto no solo con la finalidad de que el servidor web pueda delegar estas tareas y responder rápidamente al usuario, sino también para permitir una mejor escalabilidad del sistema, que entonces podrá responder a un mayor número de peticiones por unidad de tiempo.

\subsection{Arquitectura}

La arquitectura de Octopus Head consiste en cuatro capas, la capa superior o capa de presentación se ejecuta en el navegador del cliente monitor, administrador o quien sea que vea los resultados obtenidos a partir del monitoreo, esta capa se comunica con la capa dos o capa de negocio que es ejecutada por el servidor web que responde a las peticiones de los usuarios, delega tareas a la capa tres y retira y actualiza datos de la capa cuatro, la capa tres es la encargada de ejecutar tareas largas o computacionalmente intensas así como de planificar e iniciar tareas periódicas, la capa cuatro o capa de datos aloja los datos de la aplicación como usuarios, monitores, planes de monitoreo, historiales, datos recolectados de las redes, reportes, etc.

NOTA: Insertar figura de la arquitectura de la maquina servidor
\label{fig:webapp-arch}

\subsection{Modelo de la base de datos}

La base de datos de Octopus Head esencialmente modela un conjunto de monitores junto con sus enlaces monitoreados (tentáculos), los resultados obtenidos para cada tentáculo (o monitor) de cada una de sus pruebas, las pruebas y sus parámetros, el historial de cambios en el plan de monitoreo, entre otros. Ya que Django usa un ORM para manejar la base de datos, desde el punto de vista de la aplicación cada entidad es una clase por lo que es posible aprovechar todas las características de la programación orientada a objetos, como herencia de clases, clases abstractas implementación de métodos específicos a un modelos y sobrecarga de métodos de los padres, a continuación se describen las entidades que se desa modelar:

Cada usuario registrado del sistema está representado por el modelo "User" que viene incluido como parte del framework de Django, este guarda la información mínima necesaria para autenticar al usuario, así como sus grupos y permisos, un usuario autenticado puede estar en uno o mas grupos y puede tener uno o mas permisos, por defecto se tienen tres tipos de usuarios: el usuario normal, el usuario "staff" que puede ingresar la panel de administración del sistema y el superusuario, el superusuario tiene todos los privilegios del sistema, por lo tanto puede manejar otros usuarios (agregando grupos, permisos, cambiando el tipo de otros usuarios, etc) y hacer cambios a cualquier otro modelo del sistema.

Los usuarios finales del sistema (es decir aquellos que no son staff o superuser) tienen un modelo adicional llamado "UserProfile" (perfil de usuario), para implementar esta funcionalidad podría parecer conveniente sencillamente extender el modelo "User" sin embargo esto interfiere con el mecanismo de autenticacion (que no espera que exista otra tabla de usuarios) de modo que implementar una relación uno-a-uno entre el modelo "UserProfile" y el modelo "User" es preferido. El perfil de usuario aloja los detalles adicionales del usuario monitor como credenciales de Dropbox y códigos de confirmación.

El modelo central de la base de datos es el monitor, que representa un Tentacle Probe Source haciendo pruebas en la red remota. Cada usuario posee uno o mas monitores, el monitor está compuesto por un número de enlaces monitoreados y un plan de monitoreo asi como su horario de sincronizacion y sus detalles específicos como zona horaria, posición geográfica, dirección ip entre otros. 

Los tentaculos son un concepto fundamental en el enfoque de monitoreo de este trabajo, cada tentáculo (o enlace monitoreado) consiste de un Tentacle Probe Source (el monitor) y un Tentacle Probe Destination (un nodo monitoreado) y cualquier número de nodos intermedios entre ellos (como enrutadores, proxys, etc), para representar esto usamos el modelo "Link" que guarda el ip del Tentacle Probe Source y otros detalles como posición geográfica, nombre y descripción.

Las pruebas son procedimientos que el usuario puede planificar para que sus monitores ejecuten según una planificación, es a esto a lo que llamamos el 'plan de monitoreo', una prueba consiste en cualquier código python ejecutable, generalmente con el objetivo de obtener algún dato de la red monitoreada, desde el punto de vista de la aplicacion web una prueba se modela como una agregación de parámetros configurables, estos son usados para construir un formulario que permite al usuario editar el plan de monitoreo.

Los resultados de las pruebas también llamados trazas se guardan según las características especificas de cada prueba, no existe ningún limitante a la hora de diseñar modelos para los resultados de las pruebas, sin embargo las pruebas implementadas hasta ahora tienen en común un timestamp (el tiempo de ejecucion de la prueba) y el tentáculo relacionado a la prueba, sin embargo sería posible guardar trazas que no estén relacionadas a ningún tentáculo (por ejemplo, resultados del sondeo de el número de errores en una interfaz del TPS)

Un "MonitorTest" es una modelo intermedio que representa una prueba planificada para un monitor y sus parámetros, en otras palabras el conjunto de "MonitorTest" para un monitor conforman el plan de monitoreo, este modelo aloja el tiempo inicial de ejecucion de una prueba, el tiempo final, intervalo entre pruebas, y su estado (activa o inactiva). 

Ya que el usuario tiene la libertad de modificar el plan de ejecucion en cualquier momento dado, se guarda un historial de los cambios hechos a los "MonitorTest" en una tabla a modo de historial, de esta manera es posible reconstruir con que parámetros estaba siendo ejecutada una prueba en cualquier momento especifico, esto no solo con fines informativos para el usuario, sino también puede ser útil para algoritmos de análisis de los datos que necesiten conocer los parámetros de ejecucion en algún momento especifico. 

A los distintos métodos de análisis y visualización los datos que permiten al usuario explorar y obtener información relevante a partir de ellos, las llamamos visualizaciones, computar visualizaciones consiste en retirar los datos seleccionados de la base de datos, pasar estos datos por algún algoritmo de análisis y prepararlos para ser desplegados en alguna forma elegida por el usuario, como mapas de calor, gráficas de barras, mapas, etc.

Las sincronizaciones consisten en recoger los datos dejados por los monitores remotos en la nube y insertarlos a la base de datos, generalmente haciendo algún preprocesamiento o parsing, se guarda un historial de sincronizaciones no sólo como forma de informar al usuario de la cantidad de archivos recolectados y si ocurrieron errores, el mecanismo de sincronizacion depende un cursor que indica al sistema cuales son los archivos nuevos o modificados que deben ser insertados, el mecanismo de sincronizacion se explicará a fondo en la subsección \ref{sub:Recolector}. 

Como se vió en la figura \ref{fig:webapp-arch} el planificador depende de la base de datos para determinar el horario de sincronizaciones, por lo que es necesario un modelo para guardar el horario de sincronizaciones, ya sea este por intervalos o a una hora especifica del día. 

Los reportes son una forma de mostrar y compartir conjuntos de visualizaciones en una sola vista, de esta manera es posible hacer comparaciones de gráficas de distintos tentáculos, o incluso de distintos monitores y ademas compartirlas con usuarios no autenticados haciendo los resultados públicos.

\subsubsection{Diagrama de clases}

\subsubsection{Diagrama de entidad relación}

\subsubsection{Entidades}

\subsubsection{Relaciones}

\subsubsection{Optimizaciones}

\subsection{Flujo de navegación}

\subsection{Diseño de Pantallas}

\section{Componentes}

\subsection{Data Pusher}

\subsection{Recolector de datos} \label{sub:Recolector}

\subsection{Algoritmos de análisis}

\subsubsection{Cálculo de Mapas de Calor de RTT}

\subsubsection{Cálculo de horas activas}

\subsubsection{Cálculo de días activos}

\subsubsection{Cálculo de periodos de actividad continúa}

\section{Casos de Uso}

\section{Caching de gráficas}

\section{Pruebas de Rendimiento}

\chapter{Framework de integración de pruebas}

\chapter{Conclusiones y Recomendaciones}



% ***************************************************************** %
% FIN DE estructura tentativa de la Propuesta
% ***************************************************************** %

% Estilo de la bibliografï¿½a
\bibliographystyle{ieeetr}

% ***************************************************************** %
% Para agregar toda la bibliografia del archivo .bib
% solo descomente el siguiente comando
% ***************************************************************** %
\nocite{*}
% ***************************************************************** %
% Nombre del archivo con extensiï¿½n .bib en donde se almacena la bibliografï¿½a
\bibliography{bib-tesis}

% ***************************************************************** %
% FIN DE
% Cuerpo
% ***************************************************************** %

\end{document}
